\documentclass[acmsmall,screen,nonacm]{acmart}
\pdfoutput=1 

\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{verbatim}
\newcommand{\crefrangeconjunction}{--}
\usepackage{cleveref}
\usepackage{amsmath}
\usepackage{float}

\lstset{
language=Java,
basicstyle=\fontsize{9}{10}\ttfamily, 
numbers=left,
numberstyle=\tiny\color{black},
numbersep=3.5pt,
firstnumber=last,
frame=tb,
columns=fullflexible,
showstringspaces=false,
captionpos=t,
mathescape=true,
escapeinside={@}{@},
tabsize=4,
morekeywords={and,or},
commentstyle=\color{gray}\fontsize{8.5}{10},
xleftmargin=2ex,
breaklines=true,
backgroundcolor=\color{white},
}
\renewcommand{\lstlistingname}{Listing}

\newcommand{\codestyle}[1]{{{\fontsize{9}{10}\ttfamily #1}}}
\newcommand{\size}{\codestyle{size}}
\newcommand{\ins}{\codestyle{in\-sert}}
\newcommand{\del}{\codestyle{de\-lete}}
\newcommand{\contains}{\codestyle{con\-tains}}
\newcommand{\rank}{\codestyle{rank}}
\newcommand{\select}{\codestyle{select}}
\newcommand{\cas}{\texttt{CAS}}
\newcommand{\nul}{\texttt{NULL}}

\begin{document}

\title{HandshakeBST: Optimized Fast Path with Forwarding Pointers \\
for Concurrent Aggregate Queries}


\maketitle

\section{Introduction}

The implementation of efficient aggregate queries (such as \size{}, \rank{}, and \select{}) in concurrent data structures is a challenging problem. A recent breakthrough, the Lock-Free Augmented BST \cite{fatourou2024lockfree}, demonstrated that it is possible to support these queries alongside concurrent updates without sacrificing correctness. This was achieved using a system of immutable versions carrying metadata at each node. However, this approach comes with a significant performance cost: every update operation must maintain these versions, leading to high overhead even when no queries are running. Consequently, while aggregate queries are fast, standard updates become slow due to the constant maintenance of metadata.

To address this limitation, we draw inspiration from the Handshake synchronization technique \cite{sela2025handshake}. This technique allows a data structure to operate in two distinct modes: a ``fast path'' optimized for updates when no queries are present, and a ``slow path'' that enables cooperation when queries are active. The original Handshake paper demonstrated this for a simple global \size{} operation using thread-local counters.

In this work, we present \textbf{HandshakeBST} (implemented as \codestyle{MyBSTnext} in the codebase), a novel augmented Binary Search Tree that combines these two ideas. We aim to perform well in workloads where aggregate queries are rare but updates are heavy. We utilize the handshake mechanism to create a fast path where updates are lightweight and do not maintain the complex version structure. When a query is requested, the system switches to a slow path that employs the robust version-based mechanism from the Lock-Free Augmented BST paper. Unlike the original Handshake paper which only supported a global size, our implementation maintains per-node metadata, enabling complex aggregate queries like \rank{} and \select{}.

We compare our approach against the \textbf{LockFreeBST} (implemented as \codestyle{MyBSTBaseline}), which represents the state-of-the-art Lock-Free Augmented BST without the handshake optimization.

\section{Background and Related Work}

Our work builds upon the non-blocking binary search tree by Ellen et al. \cite{ellen2010nonblocking}, which introduced a practical lock-free BST using fine-grained synchronization primitives (CAS) and a cooperative helping mechanism. While highly efficient for standard updates, this structure does not natively support efficient aggregate queries. Fatourou and Ruppert \cite{fatourou2024lockfree} addressed this by introducing a general method for augmenting lock-free data structures with immutable \codestyle{Version} objects, enabling wait-free queries but imposing significant overhead on updates due to constant metadata maintenance. To mitigate this, we integrate the handshake synchronization technique proposed by Sela et al. \cite{sela2025handshake}, which allows threads to operate in a lightweight ``fast path'' when no queries are active and coordinate a transition to a ``slow path'' only when necessary. HandshakeBST combines these approaches, using the handshake mechanism to switch between a fast path that skips expensive version propagation and a slow path that maintains the robust version-based structure for consistent aggregate queries.

\section{Node Structure Extensions}


\begin{figure}[H]
\begin{lstlisting}
@\underline{class InternalNode}@:
    // Original BST fields (key, left, right, parent, info)
    fastSize: AtomicLong              // Fast path metadata
    version: Version                  // Slow path metadata (immutable snapshot)
    forwardingPtr: volatile Version   // Points to replacement Version (for chain navigation)
    reversePtr: volatile InternalNode // Points to predecessor (for chain compression optimization)

@\underline{class LeafNode}@:
    // Original BST fields (key, value, parent)
    fastSize: AtomicLong           // Always 1 for non-sentinel leaves
    version: Version               // Immutable snapshot
    // Note: Leaf nodes do NOT need forwardingPtr/reversePtr (never orphaned)

@\underline{class Version}@:  // Immutable snapshot for slow path
    left, right: Version
    nbChild: int                   // Subtree size in this snapshot
    node: reference to Node        // Back-reference to BST node
\end{lstlisting}
\caption{Node structure with forwarding pointer support}
\label{fig:node-structure-next}
\end{figure}

The \codestyle{MyBSTnext} implementation extends the standard BST node structure to support both the handshake mechanism and the forwarding pointer optimization. The \codestyle{InternalNode} and \codestyle{LeafNode} classes inherit from a base \codestyle{Node} class. Both node types contain standard BST fields (key, parent, children/value) and are augmented with specific metadata fields. The \codestyle{fastSize} field (AtomicLong) stores the subtree size maintained by fast path operations. The \codestyle{version} field holds a reference to an immutable \codestyle{Version} object, which forms the snapshot used by slow path queries. Crucially, both node types include a \codestyle{forwardingPtr} (volatile Version) and a \codestyle{reversePtr} (volatile Node). The \codestyle{forwardingPtr} is the mechanism that allows queries to navigate from an orphaned node (removed from the BST but present in the Version tree) to its replacement in the current structure. The \codestyle{reversePtr} is an optimization field used to compress chains of forwarding pointers, which will be detailed in Section 5.3.

\section{Data Structure Transformation}


\begin{figure}[H]
\begin{lstlisting}
IDLE_PHASE = -1, FAST_PHASE = -2
@\underline{class HandshakeBST}@:
    @\underline{HandshakeBST()}@:
        @Initialize BST as originally (root, sentinel nodes, etc.)@
        this.queriesPhase = 0  @// Uses mod 4 for hardware efficiency (bitwise \& 3)@
        this.opPhase = new AtomicLong[MAX_THREADS]
        this.activeReaders = 0  @// Count of active aggregate queries@
    @\underline{$fast\_op$(k)}@:  @// For @\ins{}@ or @\del{}
        @Perform the original BST operation.@
        @On successful modification at node n:@
            @Set forwarding pointer in orphaned node@
            fastUpdateMetadataOnly(delta, n.parent) @// Update ONLY fastSize (no Version updates)@
        Return the result of the original operation.
    @\underline{slow\_op(k)}@:  @// For @\ins{}@ or @\del{}
        @Perform the original BST operation.@
        @On successful modification at node n:@
            propagate(n.parent) @// Update both Version structure and nbChild to root@
        Return the result of the original operation.
@
\end{lstlisting}
\caption{HandshakeBST transformation with forwarding pointers for fast path}
\label{fig:mybstnext-transformation}
\end{figure}


\textbf{Optimization:} HandshakeBST additionally re-checks phase on every retry iteration within the operation loop, allowing faster response to concurrent handshakes during long-running operations.

The handshake protocol coordinates between fast update operations and aggregate queries, ensuring queries can safely read metadata without expensive per-operation synchronization.

\textbf{Goal of handshake:} Allow fast operations to run without synchronization overhead when no queries are active, while providing a synchronization barrier when queries need consistent snapshots.

The handshake protocol (\codestyle{\_performHandshake}, \codestyle{\_doFirstAndSecondHandshakes}) follows the handshake paper exactly. The phase cycle with modulo-4:
\begin{itemize}
\item Phase 0 (mod 4 = 0): Fast path allowed, no concurrent aggregate queries
\item Phase 1 (mod 4 = 1): First handshake - threads acknowledge transition, switch to slow path  
\item Phase 2 (mod 4 = 2): Second handshake - all threads confirmed in slow path, aggregate queries execute
\item Phase 3 (skipped): Last reader increments by 2 (phase 2 → 4 → 0 mod 4), returning to fast path
\end{itemize}
Using modulo-4 enables efficient hardware computation via bitwise AND with constant 3.

The transition mechanisms are provided by helper functions \codestyle{\_enterSlowPath()} and \codestyle{\_exitSlowPath()}, detailed in Section 4. These functions handle the coordination for queries entering and exiting slow path mode, managing the \codestyle{activeReaders} counter and phase transitions.

\section{Fast Path Implementation}

The fast path is designed to minimize synchronization overhead when no queries are active. We build up the implementation in three steps: basic metadata updates, forwarding pointers for navigation, and chain compression optimization.

\subsection{Step 1: Basic Fast Path - Metadata Updates Only}

The core of the fast path is updating \codestyle{fastSize} metadata without touching the Version tree structure. This is fundamentally different from MyBST, which performed $O(\log n)$ Version tree updates.

\begin{figure}[H]
\begin{lstlisting}
@\underline{fastUpdateMetadataOnly(delta, startNode)}@:
    current = startNode
    @\textbf{while}@ current $\neq$ null:
        @\textbf{if}@ current @\textbf{is}@ InternalNode:
            current.fastSize.addAndGet(delta)  @// Only fastSize update!@
        current = current.parent
\end{lstlisting}
\caption{Basic fast path metadata update - O(log n) atomic additions, no Version CAS}
\label{fig:fast-metadata-basic}
\end{figure}

The fundamental operation of the fast path is to update the metadata without modifying the expensive Version tree. When a fast insert or delete occurs, instead of propagating a new Version path to the root (which requires creating new objects and CAS operations), the operation simply updates the \codestyle{fastSize} counters along the path from the modified node to the root. This is done using atomic \codestyle{addAndGet} operations on the \codestyle{fastSize} field of each node. This approach avoids all object allocation and CAS contention on the Version structure, making updates significantly lighter. However, this leaves the Version tree in a stale state, which necessitates the forwarding pointer mechanism described next.

\subsection{Step 2: Adding Forwarding Pointers for Navigation}

To enable queries to navigate through structural changes made by fast operations, we add forwarding pointers that connect orphaned nodes to their replacements.

\begin{figure}[H]
\begin{lstlisting}
@\underline{helpInsert(info, useFastPath)}@:
    onLeft = (info.p.left == info.l)
    spliced = onLeft
        ? leftUpdater.compareAndSet(info.p, info.l, info.lReplacingNode)
        : rightUpdater.compareAndSet(info.p, info.l, info.lReplacingNode)
    
    @\textbf{if}@ spliced:
        info.lReplacingNode.parent = info.p
        
        @\textbf{if}@ useFastPath:
            @// STEP 1: Set forwarding pointer in orphaned node@
            @// info.l is now orphaned (replaced by info.lReplacingNode)@
            info.l.forwardingPtr = info.lReplacingNode.version
            
            @// STEP 2: Update fastSize along path@
            fastUpdateMetadataOnly(1, info.p)
        @\textbf{else}@:
            @// Slow path: Full propagation (updates structure + nbChild)@
            propagate(info.p)
    
    infoUpdater.compareAndSet(info.p, info, @\textbf{new}@ Clean())
\end{lstlisting}
\caption{Fast insert with forwarding pointer}
\label{fig:fast-insert-forwarding}
\end{figure}


\begin{figure}[H]
\begin{lstlisting}
@\underline{helpMarked(info, useFastPath)}@:
    other = (info.p.right == info.l) ? info.p.left : info.p.right
    pIsLeft = (info.gp.left == info.p)
    swung = pIsLeft
        ? leftUpdater.compareAndSet(info.gp, info.p, other)
        : rightUpdater.compareAndSet(info.gp, info.p, other)
    
    @\textbf{if}@ swung:
        other.parent = info.gp
        
        @\textbf{if}@ useFastPath:
            @// STEP 1: Set forwarding pointer in orphaned parent@
            @// info.p is now orphaned (its child 'other' was promoted)@
            info.p.forwardingPtr = other.version
            
            @// STEP 2: Update fastSize along path@
            fastUpdateMetadataOnly(-1, info.gp)
        @\textbf{else}@:
            @// Slow path: Full propagation@
            propagate(info.gp)
    
    infoUpdater.compareAndSet(info.gp, info, @\textbf{new}@ Clean())
\end{lstlisting}
\caption{Fast delete with forwarding pointer}
\label{fig:fast-delete-forwarding}
\end{figure}

As updates occur in the fast path, the structure of the BST changes (nodes are added or removed), but the Version tree—which queries use for navigation—remains static and becomes stale. This creates a disconnection: a query traversing the Version tree might reach a node that is no longer part of the valid BST, or miss a newly added node.

To bridge this gap, we introduce \textbf{Forwarding Pointers}. When a node is removed from the active BST (orphaned) during a fast update, it is not immediately discarded because it may still be referenced by the stale Version tree. We utilize this orphaned node to store a \codestyle{forwardingPtr} that points to the \codestyle{Version} of the node that replaced it in the BST.

For example, in a fast insert, the leaf node that is replaced by a new internal node (containing the old leaf and the new key) becomes orphaned. We set its \codestyle{forwardingPtr} to point to the \codestyle{Version} of the new internal node. Similarly, in a fast delete, the parent of the removed node becomes orphaned, and we set its pointer to the surviving child's \codestyle{Version}.

This allows a query traversing the stale Version tree to detect when it has reached an obsolete node. By following the \codestyle{forwardingPtr}, the query can ``jump'' from the stale snapshot to the valid, current portion of the BST (specifically, the \codestyle{Version} of the replacement node), where it can continue its traversal or read the up-to-date \codestyle{fastSize} metadata.

However, a problem arises when multiple fast operations occur in the same vicinity. A node might be replaced, and its replacement might itself be replaced shortly after, creating a chain of forwarding pointers (Node A $\to$ Node B $\to$ Node C). Traversing these chains adds overhead to queries. This motivates the need for chain compression, which we address in the next step.

\subsection{Step 3: Chain Compression with Reverse Pointers}

Multiple fast operations on the same subtree can create chains of forwarding pointers. Reverse pointers allow us to compress these chains as they form, maintaining depth $\leq$ 1.


\begin{figure}[H]
\begin{lstlisting}
@\underline{helpInsert(info, useFastPath)}@:
    onLeft = (info.p.left == info.l)
    spliced = onLeft
        ? leftUpdater.compareAndSet(info.p, info.l, info.lReplacingNode)
        : rightUpdater.compareAndSet(info.p, info.l, info.lReplacingNode)
    
    @\textbf{if}@ spliced:
        info.lReplacingNode.parent = info.p
        
        @\textbf{if}@ useFastPath:
            @// Determine the final target (follow existing chain if present)@
            finalTarget = info.lReplacingNode.version
            @\textbf{if}@ info.lReplacingNode @\textbf{is}@ InternalNode @\textbf{and}@ info.lReplacingNode.forwardingPtr $\neq$ null:
                @// Replacement already points forward - follow to end of chain@
                finalTarget = info.lReplacingNode.forwardingPtr
            
            @// Check if we're extending an existing chain (replacement has predecessor)@
            @\textbf{if}@ info.lReplacingNode @\textbf{is}@ InternalNode @\textbf{and}@ info.lReplacingNode.reversePtr $\neq$ null:
                @// Chain exists backward - update predecessor to skip intermediate nodes@
                predecessor = info.lReplacingNode.reversePtr
                predecessor.forwardingPtr = finalTarget
                @// reversePtr stays at predecessor@
            @\textbf{else}@:
                @// First link - create new chain@
                info.l.forwardingPtr = finalTarget
                @\textbf{if}@ finalTarget.node @\textbf{is}@ InternalNode:
                    finalTarget.node.reversePtr = info.l
            
            fastUpdateMetadataOnly(1, info.p)
        @\textbf{else}@:
            propagate(info.p)
    
    infoUpdater.compareAndSet(info.p, info, @\textbf{new}@ Clean())
\end{lstlisting}
\caption{Fast insert with chain compression via reverse pointers}
\label{fig:fast-insert-final}
\end{figure}


\begin{figure}[H]
\begin{lstlisting}
@\underline{helpMarked(info, useFastPath)}@:
    other = (info.p.right == info.l) ? info.p.left : info.p.right
    pIsLeft = (info.gp.left == info.p)
    swung = pIsLeft
        ? leftUpdater.compareAndSet(info.gp, info.p, other)
        : rightUpdater.compareAndSet(info.gp, info.p, other)
    
    @\textbf{if}@ swung:
        other.parent = info.gp
        
        @\textbf{if}@ useFastPath:
            @// Determine final target (follow forward chain if present)@
            finalTarget = other.version
            @\textbf{if}@ other @\textbf{is}@ InternalNode @\textbf{and}@ other.forwardingPtr $\neq$ null:
                @// Target already points forward - follow to end of chain@
                finalTarget = other.forwardingPtr
            
            @// Check if orphaned node has a predecessor in a chain@
            @\textbf{if}@ info.p.reversePtr $\neq$ null:
                @// Chain exists backward - update predecessor to skip info.p@
                predecessor = info.p.reversePtr
                predecessor.forwardingPtr = finalTarget
                @\textbf{if}@ finalTarget.node @\textbf{is}@ InternalNode:
                    finalTarget.node.reversePtr = predecessor
                @// Don't set info.p.forwardingPtr - it's skipped@
            @\textbf{else}@:
                @// First link - create new chain@
                info.p.forwardingPtr = finalTarget
                @\textbf{if}@ finalTarget.node @\textbf{is}@ InternalNode:
                    finalTarget.node.reversePtr = info.p
            
            fastUpdateMetadataOnly(-1, info.gp)
        @\textbf{else}@:
            propagate(info.gp)
    
    infoUpdater.compareAndSet(info.gp, info, @\textbf{new}@ Clean())
\end{lstlisting}
\caption{Fast delete with chain compression via reverse pointers}
\label{fig:fast-delete-final}
\end{figure}

To prevent the formation of long chains of forwarding pointers, which would degrade query performance, we implement a chain compression strategy using \textbf{Reverse Pointers}.

The \codestyle{reversePtr} field allows a node to point back to its predecessor in a forwarding chain. When a fast operation creates a new forwarding link, it checks if the replacement node is already part of an existing chain (i.e., it has a \codestyle{forwardingPtr} or \codestyle{reversePtr}).

If the replacement node already points forward to another target, the operation can ``short-circuit'' the chain by pointing the orphaned node directly to the final target. Conversely, if the orphaned node was already the target of a previous forwarding pointer (indicated by \codestyle{reversePtr}), we can update that predecessor to point directly to the new replacement.

By maintaining these reverse links, we ensure that any sequence of updates compresses the forwarding path such that the depth of any chain remains effectively constant (at most 1). This guarantees that queries never need to traverse more than one forwarding pointer to reach valid data, preserving the efficiency of the fast path even under heavy update loads.

\section{Aggregate Query Implementation}

\subsection{Shared Helper: Entering Slow Path}

All aggregate queries (\size{}, \rank{}, \select{}) share a common protocol to enter slow path mode, using \codestyle{\_doFirstAndSecondHandshakes} from the handshake paper (Section 5.1):

\begin{figure}[H]
\begin{lstlisting}
    @\underline{\_enterSlowPath()}@:
        this.activeReaders.increment()
        currPhase = this.queriesPhase.getVolatile()
        
        @// Case 1: Already in slow path - skip to next slow path cycle@
        @\textbf{if}@ currPhase\&3 == 2:
            this.queriesPhase.compareAndSet(currPhase, currPhase + 4)
            @\textbf{return}@ this.queriesPhase.getVolatile()
        
        @// Case 2: Wait for slow path transition to complete@
        @\textbf{while}@ currPhase\&3 $\neq$ 0:
            currPhase = this.queriesPhase.getVolatile()
            @\textbf{if}@ currPhase\&3 == 2:  @// Transition completed@
                @\textbf{return}@ currPhase
        
        @// Case 3: Try to win race and perform handshakes@
        @\textbf{if}@ this.queriesPhase.compareAndSet(currPhase, currPhase + 1):
            @\textbf{return}@ this.doFirstAndSecondHandshakes()  @// From handshake paper@
        @\textbf{else}@:  @// Another thread won the race@
            @\textbf{do}@:
                currPhase = this.queriesPhase.getVolatile()
            @\textbf{while}@ currPhase\&3 $\neq$ 2
            @\textbf{return}@ currPhase
\end{lstlisting}
\caption{HandshakeBST slow path entry protocol with phase conflict resolution}
\label{fig:mybstnext-enterslowpath}
\end{figure}

The \codestyle{\_enterSlowPath()} method is the gateway for all aggregate queries, ensuring they execute in a protected environment where the Version tree is consistent. It begins by incrementing \codestyle{activeReaders} to register the query's presence. It then reads the current global \codestyle{queriesPhase}.

The logic handles three distinct scenarios based on the phase state (modulo 4):
\begin{enumerate}
    \item \textbf{Already in Slow Path (Phase 2)}: If the system is already in the slow path (bits ending in 10 binary, i.e., 2), the query simply proceeds. However, if the phase counter suggests a transition is pending (e.g., a previous cycle finished but the phase wasn't incremented), it attempts to advance the phase to the next cycle to keep the state machine moving forward.
    \item \textbf{Transition in Progress (Phase 1)}: If the system is in the middle of a handshake (Phase 1), the query cannot proceed immediately. It must wait until the transition to Phase 2 is complete. This ensures that no query starts reading until all update threads have acknowledged the slow path and stopped fast updates.
    \item \textbf{Fast Path (Phase 0)}: If the system is in the fast path (Phase 0), the query attempts to initiate the transition. It uses a CAS to atomically switch the phase to 1 (First Handshake). If successful, this thread becomes the ``leader'' and executes the full handshake protocol (\codestyle{\_doFirstAndSecondHandshakes}), forcing all other threads to drain their fast operations and switch to slow mode. If the CAS fails (another thread won the race), it falls back to waiting for the winner to complete the transition.
\end{enumerate}
This mechanism guarantees that once \codestyle{\_enterSlowPath()} returns, the system is strictly in Phase 2, and all concurrent updates are performing full Version propagation.

\subsection{Shared Helper: Exiting Slow Path}

All aggregate queries share a common protocol to exit slow path mode. The last reader to finish transitions back to fast path:

\begin{figure}[H]
\begin{lstlisting}
    @\underline{\_exitSlowPath(currPhase)}@:
        remaining = this.activeReaders.decrement()
        @\textbf{if}@ remaining == 0 @\textbf{and}@ currPhase\&3 == 2:
            this.queriesPhase.compareAndSet(currPhase, currPhase + 2) @// Increment by 2@
\end{lstlisting}
\caption{HandshakeBST slow path exit protocol - last reader returns to fast path}
\label{fig:mybstnext-exitslowpath}
\end{figure}

The \codestyle{\_exitSlowPath()} method manages the return to the efficient fast path once queries are finished. It decrements the \codestyle{activeReaders} counter, which tracks the number of concurrent aggregate queries currently executing.

Crucially, the transition back to the fast path (Phase 0) is performed \textit{only} by the very last active query thread. When \codestyle{remaining} reaches zero, it indicates that no other queries are relying on the slow path snapshot. This last thread then attempts to CAS the \codestyle{queriesPhase} from Phase 2 to Phase 4 (which is equivalent to Phase 0 modulo 4).

This reference-counting approach prevents "flapping" between phases. As long as at least one query is active, the system remains in the slow path, allowing subsequent queries to execute immediately without paying the handshake cost again. Only when the system is completely idle of queries does it revert to the fast path, re-enabling lightweight updates.

\subsection{Query Navigation with Forwarding Pointers}

Queries navigate the Version tree, checking for forwarding pointers at each step to handle nodes orphaned by fast operations.

\subsubsection{Size Query}

Size is the simplest query - it only reads root metadata without tree navigation.

\begin{figure}[H]
\begin{lstlisting}
    @\underline{computeSubtreeSize(version)}@:  @// Helper to compute size of Version subtree@
        @\textbf{if}@ version == null: @\textbf{return}@ 0
        @// Combine slow (nbChild) and fast (fastSize) metadata@
        @\textbf{return}@ version.nbChild + version.node.fastSize.getVolatile()
    
    @\underline{size()}@:
    @\textbf{try}@:
        currPhase = this.\_enterSlowPath()
        @\textbf{return}@ computeSubtreeSize(this.root.version)
    @\textbf{finally}@:
        this._exitSlowPath(currPhase)
\end{lstlisting}
\caption{Size query using subtree size helper method}
\label{fig:size-with-helper}
\end{figure}


\subsubsection{Rank Query with Forwarding Navigation}

\begin{figure}[H]
\begin{lstlisting}
    @\underline{rank(k)}@:
    @\textbf{try}@:
        currPhase = this._enterSlowPath()
        snapshot = this.root.version
        @\textbf{if}@ snapshot == null: @\textbf{return}@ -1
        
        current = snapshot
        rank = 0
        
        @\textbf{while}@ current.left $\neq$ null:  @// Navigate until reaching leaf@
            @// CHECK FOR FORWARDING POINTER@
            @\textbf{if}@ current.node.forwardingPtr $\neq$ null:
                @// This node is orphaned - jump to replacement@
                replacement = current.node.forwardingPtr
                current = replacement
                @\textbf{continue}@
            
            @// Normal navigation (non-orphaned node)@
            @\textbf{if}@ k < current.key:
                current = current.left
            @\textbf{else}@:
                @// Going right: add left subtree size@
                rank += computeSubtreeSize(current.left)
                current = current.right
        
        @// Reached leaf - check if it's our key@
        @\textbf{if}@ current.key == k: @\textbf{return}@ rank + 1
        @\textbf{return}@ -1
    @\textbf{finally}@:
        this._exitSlowPath(currPhase)
\end{lstlisting}
\caption{Rank query using subtree size helper method}
\label{fig:rank-with-forwarding}
\end{figure}

The \codestyle{rank(k)} operation determines the position of a key $k$ in the sorted order of elements (1-based index). It begins by entering the slow path to secure a consistent snapshot of the tree via \codestyle{root.version}. The algorithm then traverses this Version tree from the root down to the leaves. At each step, it first checks for a \codestyle{forwardingPtr} to handle any nodes that may have been orphaned by concurrent fast updates; if one exists, it jumps to the replacement node. If the node is valid, it compares the search key $k$ with the current node's key. If $k$ is smaller, it moves to the left child. If $k$ is larger, it adds the size of the left subtree (calculated via \codestyle{computeSubtreeSize}) to the running rank total and moves to the right child. This process continues until a leaf is reached. If the leaf matches $k$, the final rank is returned; otherwise, the key is not found.

\subsubsection{Select Query with Forwarding Navigation}

\begin{figure}[H]
\begin{lstlisting}
    @\underline{select(k)}@:
    @\textbf{try}@:
        currPhase = this._enterSlowPath()
        snapshot = this.root.version
        @\textbf{if}@ snapshot == null: @\textbf{return}@ null
        
        current = snapshot
        remaining = k
        
        @\textbf{while}@ current.left $\neq$ null:  @// Navigate until reaching leaf@
            @// CHECK FOR FORWARDING POINTER@
            @\textbf{if}@ current.node.forwardingPtr $\neq$ null:
                @// This node is orphaned - jump to replacement@
                replacement = current.node.forwardingPtr
                current = replacement
                @\textbf{continue}@
            
            @// Normal navigation (non-orphaned node)@
            @// Calculate left subtree size using helper@
            leftSize = computeSubtreeSize(current.left)
            
            @\textbf{if}@ remaining $\leq$ leftSize:
                current = current.left
            @\textbf{else}@:
                remaining -= leftSize
                current = current.right
        
        @// Reached leaf@
        @\textbf{if}@ current.key $\neq$ null @\textbf{and}@ remaining == 1: @\textbf{return}@ current.key
        @\textbf{return}@ null
    @\textbf{finally}@:
        this._exitSlowPath(currPhase)
\end{lstlisting}
\caption{Select query using subtree size helper method}
\label{fig:select-with-forwarding}
\end{figure}

The \codestyle{select(k)} operation finds the key with the $k$-th smallest value in the tree. Like \codestyle{rank}, it starts by entering the slow path and obtaining the \codestyle{root.version} snapshot. It maintains a \codestyle{remaining} count, initially set to $k$. As it traverses down the Version tree, it constantly checks for and follows \codestyle{forwardingPtrs} to ensure it is reading valid metadata. At each internal node, it computes the size of the left subtree. If \codestyle{remaining} is less than or equal to this left size, the target key lies in the left subtree, so it descends left. Otherwise, it subtracts the left size from \codestyle{remaining} and descends right. This continues until a leaf is reached. If the leaf represents a valid key and \codestyle{remaining} is 1, that key is returned; otherwise, the index is out of bounds.

\section{Contains Implementation}

\codestyle{contains} (or \codestyle{get}) operations are read-only and must execute efficiently without handshakes while ensuring correct linearization with concurrent slow operations. The implementation varies by phase.


\begin{figure}[H]
\begin{lstlisting}
@\underline{get(k)}@:
    currentPhase = this.queriesPhase.getVolatile()
    
    @// Phase 2: Use Version tree navigation (slow contains)@
    @\textbf{if}@ currentPhase\&3 == 2:
        @// Navigate Version tree to find key@
        result = getViaVersionTree(k)
        
        @// After getting result, check if we're still in a slow phase@
        exitPhase = this.queriesPhase.getVolatile()
        @\textbf{if}@ (exitPhase\&3) == 2:
            @// Still in a slow phase - result is valid@
            @\textbf{return}@ result
        @\textbf{else}@:
            @\textbf{if}@ (exitPhase\&3) == 0:
                @\textbf{return}@ result  @// Fast path - no phase change
            @\textbf{else}:
                @\textbf{return}@ get(k)  @// Tail recursion - retry@
    
    @// Phase 0 or 1: Use BST navigation (fast contains)@
    l = root.left
    @\textbf{while}@ l @\textbf{is}@ InternalNode:
        l = (k < l.key) ? l.left : l.right
    
    @// If we started in Phase 1, check if we transitioned to slow path@
    @\textbf{if}@ (currentPhase\&3) == 1:
        @\textbf{if}@ (this.queriesPhase.getVolatile()\&3) == 2:
            @\textbf{return}@ get(k)  @// Retry@
        @\textbf{else}@:
            @\textbf{if}@ l.key == k: @\textbf{return}@ l.value
    @\textbf{else}@:
        @\textbf{if}@ l.key == k: @\textbf{return}@ l.value
    
    @\textbf{return}@ null  @// Key not found@

@\underline{getViaVersionTree(k)}@:  @// Helper for phase 2 Version tree navigation@
    version = root.version
    @\textbf{if}@ version == null: @\textbf{return}@ null
    
    @\textbf{while}@ version.left $\neq$ null:
        version = (k < version.key) ? version.left : version.right
    
    @\textbf{if}@ version.key == k:
        @\textbf{return}@ version.node.value
    @\textbf{return}@ null
\end{lstlisting}
\caption{Complete contains implementation with phase validation}
\label{fig:contains-complete}
\end{figure}

The design of the \codestyle{contains} operation is driven by the requirement for high performance and wait-freedom. Unlike aggregate queries, which are relatively rare and can afford the overhead of the handshake protocol (incrementing \codestyle{activeReaders}, checking phases), \codestyle{contains} operations are frequent and must remain lightweight.

\paragraph{Optimistic Execution without Registration}
A naive approach would be to have \codestyle{contains} participate in the handshake protocol—incrementing \codestyle{activeReaders} to prevent the system from switching to the fast path while the query is running. However, this would introduce significant contention on the \codestyle{activeReaders} counter and couple the performance of read operations to the state of the handshake. Instead, we adopt an \textit{optimistic} approach: \codestyle{contains} does not register itself. It observes the current phase, executes the appropriate traversal strategy, and validates the result at the end.

\paragraph{Handling the Fast Path (Phase 0 and 1)}
When the system is in the Fast Path (Phase 0) or the First Handshake (Phase 1), \codestyle{contains} behaves like a standard lock-free BST search. It traverses the physical \codestyle{Node} structure. This is safe because both fast and slow updates maintain the structural integrity of the BST at all times. Even if a slow update is in progress, the physical tree remains a valid search structure.

A special case arises in Phase 1. If a \codestyle{contains} operation starts in Phase 1, it is racing with a transition to the Slow Path. If the system completes the transition to Phase 2 while the \codestyle{contains} is still running, there is a risk of inconsistency regarding the linearization order of concurrent operations. To address this, if we detect that the phase has switched to Phase 2 upon completion, we simply retry the operation.

\paragraph{Handling the Slow Path (Phase 2)}
When the system is in the Slow Path, \codestyle{contains} leverages the \codestyle{Version} tree. Traversing the immutable \codestyle{Version} snapshot is advantageous as it avoids contention with concurrent slow updates. However, a concurrency hazard exists: since the operation is not registered, the system might transition back to the Fast Path (Phase 0) \textit{during} the traversal.

If this transition occurs, fast updates could resume immediately. These fast updates modify the physical tree and add forwarding pointers but do \textit{not} update the \codestyle{Version} structure that the slow \codestyle{contains} is traversing. Consequently, the \codestyle{contains} operation could be traversing a stale path and miss a node that was inserted or removed by a fast update.

To solve this without locks or reference counting, we use \textbf{phase validation}. We capture the \codestyle{queriesPhase} before starting the traversal. After the result is obtained, we read the phase again.
\begin{itemize}
    \item \textbf{Validation Success:} If the phase remains exactly the same, we know the system stayed in the Slow Path for the duration of the operation. Since fast updates are impossible in the Slow Path, the \codestyle{Version} tree snapshot remained valid, and the result is correct.
    \item \textbf{Validation Failure:} If the phase has changed, it implies the system may have cycled through the Fast Path. Since we cannot guarantee that we didn't miss a fast update, we discard the result and retry the operation.
\end{itemize}

This design ensures that \codestyle{contains} is always linearizable while paying the cost of retries only during the rare moments of phase transition.




\section{Linearizability and Correctness}


Following the augmented BST paper, we define arrival points to track when update operations' effects become visible in the metadata at each node. The linearization order is then defined by arrival points at the root:

\begin{itemize}
\item Update operations: Linearized at their arrival point at the root node
\item Queries: Linearized when they obtain a snapshot by reading \codestyle{root.version}
\end{itemize}

The arrival point of an update operation at a node $x$ occurs when both conditions hold:
\begin{enumerate}
\item Node $x$ is on the search path for the operation's key
\item The operation's effect is reflected in the metadata accessible from \codestyle{x.version} (either directly via \codestyle{nbChild}, or indirectly via \codestyle{fastSize} and forwarding pointers)
\end{enumerate}


We organize the linearization analysis by handshake phase, showing which operations can execute concurrently in each phase and their linearization points.

\subsection{Phase 0: Fast Path}

When \codestyle{queriesPhase \& 3 == 0}, the system is in fast path mode. The following operations can execute concurrently:

\paragraph{Fast insert/delete:}

\textit{Linearization point:} Original BST linearization point (CAS on \codestyle{parent.info} succeeds).

\textit{Concurrent operations:} Other fast operations, contains/get.

\textit{Correctness:} Multiple fast operations use base lock-free BST synchronization (CAS, helping). Each updates independent metadata: sets one forwarding pointer (volatile write) and updates \codestyle{fastSize} (atomic additions). No CAS conflicts on Version nodes.


\paragraph{Slow insert/delete:}

Slow operations that **started in Phase 2** may still be executing \codestyle{propagate()} when system returns to Phase 0 (last query finished and decremented \codestyle{activeReaders} to 0).

\textit{Linearization point:} Original BST CAS (structural modification point). Like in Phase 1

\textit{Concurrent operations:} Fast operations (new, starting in Phase 0), contains/get.


\paragraph{Contains/get:}

\textit{Linearization point:} When the operation returns the node.

\textit{Correctness in Phase 0:} Contains correctness depends on what it is concurrent with:

\begin{itemize}
\item \textbf{Concurrent with fast updates:} Correct per lock-free BST paper. Contains navigates BST structure using standard lock-free traversal, which remains consistent.

\item \textbf{Concurrent with slow updates:} Correct per lock-free BST paper. Slow updates modify the BST structure using the same CAS operations as fast updates, ensuring consistent traversal for contains.

\item \textbf{Slow contains from Phase 2 still running in Phase 0:} A contains that started in Phase 2 and is still navigating the Version tree when phase transitions to 0 will detect the phase change (checking if exit phase is still slow) and retry. On retry, it uses fast path BST navigation which is correct concurrent with fast updates.
\end{itemize}

\paragraph{Aggregate queries (size/rank/select):}

Cannot execute in Phase 0. Any query calling \codestyle{\_enterSlowPath()} will trigger transition to Phase 1.



\subsection{Phase 1: First Handshake}

When \codestyle{queriesPhase \& 3 == 1}, a query has initiated the transition to slow path. The first handshake is in progress - threads are acknowledging the transition. The following operations can execute concurrently:

\paragraph{Fast insert/delete:}

These are fast operations that **read phase $\equiv_4$ 0** (started in Phase 0) but are still executing during Phase 1 transition.

\textit{Linearization point:} Original BST CAS on \codestyle{parent.info} (same as Phase 0).

\textit{Concurrent operations:} Other fast operations (from Phase 0), slow operations (starting in Phase 1), contains/get.

\textit{Correctness:} Operations that started in Phase 0 continue as fast operations even during Phase 1. They can be concurrent with slow operations that read phase 1 and begin propagating. This is safe because they touch different metadata fields.

\paragraph{Slow insert/delete:}

These are slow operations that **read phase $\equiv_4$ 1** at the start (initiated during Phase 1).

\textit{Linearization point:} Original BST CAS (structural modification point).

\textit{Concurrent operations:} Fast operations (started in Phase 0, still executing), other slow operations, contains/get.

\textit{Correctness - Concurrent fast and slow:} Slow operations starting in Phase 1 can be concurrent with fast operations that started in Phase 0. This is safe because:
\begin{itemize}
\item Slow operation linearized at its BST CAS
\item Fast operations (from Phase 0) linearized at their BST CAS points  
\item Ordering by CAS timestamps: operations ordered by when their BST CAS succeeds
\item Slow operation's \codestyle{propagate()} updates \codestyle{node.version} (new Versions with \codestyle{nbChild})
\item Fast operations update \codestyle{node.fastSize} and \codestyle{forwardingPtr}
\item No conflicts - different metadata fields
\end{itemize}

This follows the handshake paper's treatment (Figure 24) where operations that start in different phases can execute concurrently during the transition. Multiple slow operations may CAS conflict on \codestyle{node.version}, handled by retry logic in \codestyle{propagate()}.

\paragraph{Contains/get:}

Contains uses the same logic as Phase 0 (see Section 5 for complete implementation)

\paragraph{Aggregate queries:}

Blocked - waiting for Phase 1 to complete before transitioning to Phase 2.

\subsection{Phase 2: Slow Path}

When \codestyle{queriesPhase \& 3 == 2}, the second handshake is complete. All threads have acknowledged slow path. The following operations can execute concurrently:

\paragraph{Fast insert/delete:}

Cannot execute - all threads that read phase $\equiv_4$ 2 use slow path.

\paragraph{Slow insert/delete:}

\textit{Linearization point:} When operation reads phase $\equiv_4$ 2: linearized when \codestyle{propagate()} reaches root (arrival point at root).

\textit{Concurrent operations:} Aggregate queries (executing), other slow operations.

\textit{Correctness - Retrospective linearization:}

Following augmented BST paper, linearization is when \codestyle{propagate()} reaches root. Ordering may be adjusted retrospectively:
\begin{itemize}
\item No concurrent query: Operation linearized at \codestyle{propagate()} completion
\item Query concurrent with \codestyle{propagate()}:
    \begin{itemize}
    \item Query reads \codestyle{root.version} after \codestyle{propagate()} completes $\Rightarrow$ query sees update $\Rightarrow$ operation linearized at \codestyle{propagate()} time
    \item Query reads \codestyle{root.version} before \codestyle{propagate()} completes $\Rightarrow$ query doesn't see update $\Rightarrow$ operation retrospectively ordered after query (even though arrival point at root is later)
    \end{itemize}
\end{itemize}


\paragraph{Aggregate queries (size/rank/select):}

\textit{Linearization point:} When query reads \codestyle{root.version} (after \codestyle{\_enterSlowPath()} completes both handshakes).

\textit{Concurrent operations:} Only slow operations (all fast operations finished or switched to slow path).

\textit{Correctness - Snapshot consistency:}
\begin{itemize}
\item \codestyle{\_enterSlowPath()} completes both handshakes - no fast operations executing
\item Query reads \codestyle{root.fastSize} and \codestyle{root.version} - forms atomic snapshot
\item Navigation follows potentially stale Version tree, using forwarding pointers to reach current nodes
\item For orphaned nodes: combines \codestyle{Version.nbChild} (slow) + replacement's \codestyle{fastSize} (fast)
\item Handshake ensures all forwarding pointers written before query's linearization point
\end{itemize}

All three query types (\size{}, \rank{}, \select{}) share the same linearization semantics.

\paragraph{Contains/get:}

\textit{Implementation:} In Phase 2, \codestyle{contains} uses Version tree navigation (like aggregate queries) instead of BST navigation:


\textit{Linearization point:} When reads \codestyle{root.version} (obtains immutable snapshot).

\textit{Correctness:} Uses immutable Version tree snapshot, ensuring consistency with concurrent aggregate queries and slow operations. No dependency issues because snapshot is atomic and immutable. This is safe and correct - \codestyle{contains} becomes a "slow contains" that navigates the Version tree rather than the BST, avoiding races with concurrent slow operations that are modifying BST structure.


\section{Experimental Evaluation}

We evaluated HandshakeBST's performance compared to baseline approaches, measuring both operational overhead and query scalability. 


\begin{itemize}
\item \textbf{Read-heavy}: 3\% \ins{}, 2\% \del{}, 95\% \contains{}
\item \textbf{Update-heavy}: 30\% \ins{}, 20\% \del{}, 50\% \contains{}
\end{itemize}


\Cref{fig:mybst-overhead-a} and \Cref{fig:mybst-overhead-b} present the throughput measurements comparing HandshakeBST (\codestyle{MyBSTnext}) against the baseline LockFreeBST (\codestyle{MyBSTBaseline}) and a standard non-augmented BST. The results reveal three distinct performance regimes:

\paragraph{Regime 1: Pure Fast Path (No Concurrent Queries)}
In the absence of aggregate queries (top row of \Cref{fig:mybst-overhead-a}), HandshakeBST demonstrates its primary design advantage. By avoiding the creation and propagation of \codestyle{Version} objects for every update, it achieves significantly higher throughput than the baseline. In the update-heavy workload (30\% insert, 20\% delete), HandshakeBST reaches approximately 5.0 million operations/second with 32 threads, compared to just 1.3 million for the baseline—a nearly $4\times$ speedup. This confirms that the fast path successfully eliminates the heavy metadata overhead of the augmented BST when it is not needed.

\paragraph{Regime 2: Worst-Case Contention (Continuous Queries)}
When a concurrent thread performs \size{} queries continuously with zero delay (bottom row of \Cref{fig:mybst-overhead-a}), the system is forced to constantly switch phases or remain in the slow path. In this scenario, HandshakeBST's performance drops significantly (to $\approx$ 0.8M ops/sec in update-heavy), falling below the baseline ($\approx$ 1.35M ops/sec). This represents the worst-case scenario for the handshake protocol, where the overhead of coordination and the inability to utilize the fast path outweigh the benefits. The baseline, being a uniform wait-free structure, handles this constant contention more gracefully.

\paragraph{Regime 3: Realistic Workload (Occasional Queries)}
The third scenario (top row of \Cref{fig:mybst-overhead-b}) introduces a small $700\mu s$ delay between size queries, simulating a more realistic usage pattern where aggregate queries are frequent but not continuous. Here, HandshakeBST recovers its performance advantage. In the update-heavy workload, throughput rebounds to $\approx$ 4.5M ops/sec, far outperforming the baseline's $\approx$ 1.25M ops/sec. This demonstrates that even a brief window of fast path execution is sufficient to amortize the cost of the handshake, allowing the data structure to deliver "best of both worlds" performance: near-optimal update speeds most of the time, with the capability to service consistent aggregate queries when requested.

\begin{figure*}[!ht]
    \centering
    \medskip
    \textit{Read heavy}\quad\quad\quad
    \includegraphics[height=.02\textwidth]{BST/legend_overhead.png}\quad\quad\quad
    \textit{Update heavy}\par
    \medskip

    \text{Without a concurrent \size{} thread}\par
    \smallskip
    \includegraphics[width=.45\textwidth,trim={0 0 0 .1cm}]{BST/overhead_united_BST_1000000setSize_3ins-2rem_0sizeThreads_0delay.png}\hspace{2.5em}
    \includegraphics[width=.45\textwidth,trim={0 0 0 .1cm}]{BST/overhead_united_BST_1000000setSize_30ins-20rem_0sizeThreads_0delay.png}\par
    \includegraphics[width=.45\textwidth,trim={0 0 0 .2cm}]{BST/overhead_united_bar_BST_1000000setSize_3ins-2rem_0sizeThreads_0delay.png}\hspace{2.5em}
    \includegraphics[width=.45\textwidth,trim={0 0 0 .2cm}]{BST/overhead_united_bar_BST_1000000setSize_30ins-20rem_0sizeThreads_0delay.png}\par

    \medskip
    \text{With a concurrent \size{} thread and no delay}\par
    \smallskip
    \includegraphics[width=.45\textwidth,trim={0 0 0 .1cm}]{BST/overhead_united_BST_1000000setSize_3ins-2rem_1sizeThreads_0delay.png}\hspace{2.5em}
    \includegraphics[width=.45\textwidth,trim={0 0 0 .1cm}]{BST/overhead_united_BST_1000000setSize_30ins-20rem_1sizeThreads_0delay.png}\par
    \includegraphics[width=.45\textwidth,trim={0 0 0 .2cm}]{BST/overhead_united_bar_BST_1000000setSize_3ins-2rem_1sizeThreads_0delay.png}\hspace{2.5em}
    \includegraphics[width=.45\textwidth,trim={0 0 0 .2cm}]{BST/overhead_united_bar_BST_1000000setSize_30ins-20rem_1sizeThreads_0delay.png}\par

    \caption{Overhead on BST operations with HandshakeBST and baseline methodologies (Part 1)}
    \label{fig:mybst-overhead-a}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \medskip
    \textit{Read heavy}\quad\quad\quad
    \includegraphics[height=.02\textwidth]{BST/legend_overhead.png}\quad\quad\quad
    \textit{Update heavy}\par
    \medskip

    \text{With a concurrent \size{} thread and 700 $\mu$s delay}\par
    \smallskip
    \includegraphics[width=.45\textwidth,trim={0 0 0 .1cm}]{BST/overhead_united_BST_1000000setSize_3ins-2rem_1sizeThreads_700delay.png}\hspace{2.5em}
    \includegraphics[width=.45\textwidth,trim={0 0 0 .1cm}]{BST/overhead_united_BST_1000000setSize_30ins-20rem_1sizeThreads_700delay.png}\par
    \includegraphics[width=.45\textwidth,trim={0 0 0 .2cm}]{BST/overhead_united_bar_BST_1000000setSize_3ins-2rem_1sizeThreads_700delay.png}\hspace{2.5em}
    \includegraphics[width=.45\textwidth,trim={0 0 0 .2cm}]{BST/overhead_united_bar_BST_1000000setSize_30ins-20rem_1sizeThreads_700delay.png}\par

    \caption{Overhead on BST operations with HandshakeBST and baseline methodologies (Part 2)}
    \label{fig:mybst-overhead-b}
\end{figure*}

\subsection{Size Scalability}

We also evaluated the scalability of the \size{} operation by varying the number of concurrent size threads from 1 to 32, while maintaining 32 workload threads. We focus on the 0-delay scenario (continuous size queries) to stress-test the synchronization mechanism.

\begin{figure*}[!ht]
    \centering
    \medskip
    \textit{Read heavy}\hspace{3.3em}
    \includegraphics[height=.021\textwidth]{BST/legend_scalability.png}\hspace{3.3em}
    \textit{Update heavy}
    \includegraphics[width=.45\textwidth,trim={0 0 0 .1cm}]{BST/scalability_sizeThreads_BST_1000000setSize_3ins-2rem_32workloadThreads_0delay.png}\hspace{2.5em}
    \includegraphics[width=.45\textwidth,trim={0 0 0 .1cm}]{BST/scalability_sizeThreads_BST_1000000setSize_3ins-2rem_32workloadThreads_0delay.png}\vspace{-1.2em}
    \caption{Size scalability in BST (0 delay)}
    \label{fig:mybst-scalability}
\end{figure*}

As shown in \Cref{fig:mybst-scalability}, HandshakeBST demonstrates scalability as the number of size threads increases. In the 0-delay scenario, the system frequently enters the slow path (Phase 2) to service size queries. While the initial transition to the slow path involves the overhead of the handshake mechanism, this cost is amortized when multiple size threads are active. Once the immutable version tree snapshot is established, multiple concurrent size threads can navigate it in parallel without interfering with each other or blocking on further synchronization. This allows the aggregate throughput of the size operation to increase with the number of threads, confirming that the snapshot-based approach effectively supports concurrent aggregate queries under high load.

\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}

\end{document}
